import time
import csv
import pandas as pd
 
from selenium import webdriver
from selenium.common.exceptions import UnexpectedAlertPresentException
from selenium.webdriver.common.keys import Keys

 
# driver = webdriver.Firefox(executable_path='<Path>/geckodriver.exe')
# This block of code is used to block the notification popup which is generated by site
options = webdriver.ChromeOptions()
options.add_argument("--disable-notifications")
 
# to open chrome webbrowser and maximize the window
driver = webdriver.Chrome(executable_path="chromedriver.exe", chrome_options=options)
driver.maximize_window()
 
#Implicit Wait when element is taking time to load
driver.implicitly_wait(20)
 
# connect to the root web address
driver.get("https://scholar.google.com/citations?hl=en&view_op=search_authors&mauthors=Computer+Science+professors&btnG=")
#we define a variable for list of links so that after getting all links we loop through it to extract name and h-index
list_of_links = []
total_name = []
total_h_index = []

#the for loop allows the code to run across 25 pages
for i in range (25):
    print("page "+str(i+1))   #adds 1 since programming starts counting from 0
    next = driver.find_element_by_xpath("//div/button[2]")  #locates the next page button
    time.sleep(4)   #time.sleep() is to create delay to avoiding google flagging in suspicion of robot stuff
    profileList = driver.find_elements_by_xpath("//div/h3/a")
    time.sleep(6)
    for profile in profileList:
        time.sleep(3)
        p_url = profile.get_attribute("href")  #this extracts the attribute of h ref which is the profile link
        time.sleep(3)
        list_of_links.append(p_url)  
        time.sleep(3)
    next.send_keys(Keys.END) #goes down to where next page is if not stale element error will occur

    next.click() #clicks the next page
    time.sleep(10)
print("You have "+len(list_of_links)+" queries")
for each in list_of_links:
    driver.get(each) #goes to each link
    try:
        name = driver.find_element_by_id("gsc_prf_in").text #gets the container of name and the text which is the name
        total_name.append(name)
        time.sleep(6)
    except:
        total_name.append("No Data")  #inserts no data in list in a case whereby it doesn't find name to prevent the code from crashing
    time.sleep(7)
    try:
        h_index = driver.find_element_by_xpath("//*[@id='gsc_rsb_st']/tbody/tr[2]/td[2]").text #gets the container of h-index and the text which is the h-index
        total_h_index.append(h_index)
        time.sleep(10)
    except:
        total_name.append("No Data") #inserts no data in list in a case whereby it doesn't find h-index to prevent the code from crashing
    time.sleep(10)


print(total_name)
print(total_h_index)


df = pd.DataFrame({'Names': total_name,
                   'H Index': total_h_index})  #defines columns for storing the Names and H-index using pandas.
df.to_csv('output.csv') #specifies the name of the csv file

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "TEAM B TASK 6\n",
    "\"\"\"\n",
    "import time\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This block of code is used to block the notification popup which is generated by site\n",
    "OPTIONS = webdriver.ChromeOptions()\n",
    "OPTIONS.add_argument(\"--disable-notifications\")\n",
    "# to open chrome webbrowser and maximize the window\n",
    "DRIVER = webdriver.Chrome(executable_path=\"chromedriver.exe\", options=OPTIONS)\n",
    "DRIVER.maximize_window()\n",
    "#Implicit Wait when element is taking time to load\n",
    "DRIVER.implicitly_wait(20)\n",
    "# connect to the root web address\n",
    "DRIVER.get(\"https://scholar.google.com/citations?hl=en&view_op=search_authors&mauthors=Computer+Science+professors&btnG=\")\n",
    "#we define a variable for list of links so that after getting all links\n",
    "#we loop through it to extract name and h-index\n",
    "LIST_OF_LINKS = []\n",
    "TOTAL_NAME = []\n",
    "TOTAL_BIO = []\n",
    "TOTAL_H_INDEX = []\n",
    "H_INDEX_2014 = []\n",
    "TOTAL_I_10_INDEX = []\n",
    "I_10_INDEX_2014 = []\n",
    "TOTAL_CITATIONS = []\n",
    "#the for loop allows the code to run across 25 pages\n",
    "#this part is just to collect the urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(25):\n",
    "    print(\"collecting page \"+str(i+1))\n",
    "    #adds 1 since programming starts counting from 0\n",
    "    next_page = DRIVER.find_element_by_xpath(\"//div/button[2]\")\n",
    "#locates the next page button\n",
    "    time.sleep(4)\n",
    "#time.sleep() is to create delay to avoiding google flagging\n",
    "    profileList = DRIVER.find_elements_by_xpath(\"//div/h3/a\")\n",
    "    time.sleep(6)\n",
    "    for profile in profileList:\n",
    "        time.sleep(3)\n",
    "        p_url = profile.get_attribute(\"href\")\n",
    "#this extracts the attribute of h ref which is the profile link\n",
    "        time.sleep(3)\n",
    "        LIST_OF_LINKS.append(p_url)\n",
    "        time.sleep(3)\n",
    "    next_page.send_keys(Keys.END)\n",
    "#goes down to where next page is if not stale element error will occur\n",
    "    next_page.click() #clicks the next page\n",
    "    time.sleep(10)\n",
    "print(\"You have \"+str(len(LIST_OF_LINKS))+\" queries\")\n",
    "#this is just the beginning of scraping each of them to extract the name and h-index\n",
    "for each in LIST_OF_LINKS:\n",
    "    print(\"collecting data of \"+str(int(LIST_OF_LINKS.index(each))+1))\n",
    "    DRIVER.get(each) #goes to each link\n",
    "    try:\n",
    "        name_path = \"gsc_prf_in\"\n",
    "        name = DRIVER.find_element_by_id(name_path).text\n",
    "        #gets the container of name and the text which is the name\n",
    "        TOTAL_NAME.append(name)\n",
    "        time.sleep(6)\n",
    "    except Exception as _e:\n",
    "        TOTAL_NAME.append(\"No Data\")\n",
    "#inserts no data in list in a case whereby it doesn't find name to prevent the code from crashing\n",
    "    time.sleep(7)\n",
    "    try:\n",
    "        bio_path = \"//*[@id='gsc_prf_i']/div[2]\"\n",
    "        bio = DRIVER.find_element_by_xpath(bio_path).text\n",
    "        TOTAL_BIO.append(bio)\n",
    "    except Exception as _e:\n",
    "        TOTAL_BIO.append(\"No Data\")\n",
    "    try:\n",
    "        h_index_path = \"//*[@id='gsc_rsb_st']/tbody/tr[2]/td[2]\"\n",
    "        h_index = DRIVER.find_element_by_xpath(h_index_path).text\n",
    "#gets the container of total h-index and the text which is the total h-index\n",
    "        TOTAL_H_INDEX.append(h_index)\n",
    "        time.sleep(10)\n",
    "    except Exception as _e:\n",
    "        TOTAL_H_INDEX.append(\"No Data\") #inserts no data in list in a case whereby\n",
    "#it doesn't find h-index to prevent the code from crashing\n",
    "    try:\n",
    "        h_index_2014_path = \"//*[@id='gsc_rsb_st']/tbody/tr[2]/td[3]\"\n",
    "        each_h_index_2014 = DRIVER.find_element_by_xpath(h_index_2014_path).text\n",
    "#gets the container of 2014 h-index and the text which is the 2014 h-index\n",
    "        H_INDEX_2014.append(each_h_index_2014)\n",
    "        time.sleep(10)\n",
    "    except Exception as _e:\n",
    "        H_INDEX_2014.append(\"No Data\")\n",
    "#inserts no data in list in a case whereby it doesn't find h-index to prevent the code from crashing\n",
    "    try:\n",
    "        i_10_index_path = \"//*[@id='gsc_rsb_st']/tbody/tr[3]/td[2]\"\n",
    "        i_10_index = DRIVER.find_element_by_xpath(i_10_index_path).text\n",
    "        #gets the container of h-index and the text which is the h-index\n",
    "        TOTAL_I_10_INDEX.append(i_10_index)\n",
    "        time.sleep(10)\n",
    "    except Exception as _e:\n",
    "        TOTAL_I_10_INDEX.append(\"No Data\")\n",
    "#inserts no data in list in a case whereby it doesn't find h-index to prevent the code from crashing\n",
    "    try:\n",
    "        i_10_index_2014_path = \"//*[@id='gsc_rsb_st']/tbody/tr[3]/td[3]\"\n",
    "        each_i_10_index_2014 = DRIVER.find_element_by_xpath(i_10_index_2014_path).text\n",
    "        #gets the container of h-index and the text which is the h-index\n",
    "        I_10_INDEX_2014.append(each_i_10_index_2014)\n",
    "        time.sleep(10)\n",
    "    except Exception as _e:\n",
    "        I_10_INDEX_2014.append(\"No Data\")\n",
    "#inserts no data in list in a case whereby it doesn't find h-index to prevent the code from crashing\n",
    "    try:\n",
    "        each_total_citations_path = \"//*[@id='gsc_rsb_st']/tbody/tr[1]/td[2]\"\n",
    "        each_total_citations = DRIVER.find_element_by_xpath(each_total_citations_path).text\n",
    "        #gets the container of h-index and the text which is the h-index\n",
    "        TOTAL_CITATIONS.append(each_total_citations)\n",
    "        time.sleep(10)\n",
    "    except Exception as _e:\n",
    "        TOTAL_CITATIONS.append(\"No Data\")\n",
    "#inserts no data in list in a case whereby it doesn't find h-index to prevent the code from crashing\n",
    "time.sleep(10)\n",
    "print(TOTAL_NAME)\n",
    "print(TOTAL_BIO)\n",
    "print(TOTAL_H_INDEX)\n",
    "print(H_INDEX_2014)\n",
    "print(TOTAL_I_10_INDEX)\n",
    "print(I_10_INDEX_2014)\n",
    "print(TOTAL_CITATIONS)\n",
    "DF = pd.DataFrame({'Names': TOTAL_NAME,\n",
    "                   'Bio Data': TOTAL_BIO,\n",
    "                   'H Index': TOTAL_H_INDEX,\n",
    "                   'H Index sice 2014': H_INDEX_2014,\n",
    "                   'I-10 Index': TOTAL_I_10_INDEX,\n",
    "                   'I-10 Index since 2014': I_10_INDEX_2014,\n",
    "                   'Citation': TOTAL_CITATIONS,\n",
    "                   })  #defines columns for storing the Names and H-index using pandas.\n",
    "DF.to_csv('output.csv') #specifies the name of the csv file"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
